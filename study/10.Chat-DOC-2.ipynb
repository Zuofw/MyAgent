{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-21T06:54:56.563937Z",
     "start_time": "2025-11-21T06:54:41.818095Z"
    }
   },
   "source": [
    "# 导入必须的包\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader, Docx2txtLoader, PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_openai import  ChatOpenAI\n",
    "# 导入聊天所需的模块\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 定义chatdoc\n",
    "class ChatDoc():\n",
    "    def __init__(self):\n",
    "        self.doc = None\n",
    "        self.splitText = []  # 分割后的文本\n",
    "        self.template = [\n",
    "            (\"system\", \"你是一个处理文档的秘书,你从不说自己是一个大模型或者AI助手,你会根据下面提供的上下文内容来继续回答问题.\\n 上下文内容\\n {context} \\n\"),\n",
    "            (\"human\", \"你好！\"),\n",
    "            (\"ai\", \"你好\"),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "        self.prompt = ChatPromptTemplate.from_messages(self.template)\n",
    "\n",
    "    def getFile(self):\n",
    "        doc = self.doc\n",
    "        loaders = {\n",
    "            \"docx\": Docx2txtLoader,\n",
    "            \"pdf\": PyPDFLoader,\n",
    "            \"xlsx\": UnstructuredExcelLoader,\n",
    "        }\n",
    "        file_extension = doc.split(\".\")[-1]\n",
    "        loader_class = loaders.get(file_extension)\n",
    "        if loader_class:\n",
    "            try:\n",
    "                loader = loader_class(doc)\n",
    "                text = loader.load()\n",
    "                return text\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_extension} files:{e}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Unsupported file extension: {file_extension}\")\n",
    "            return None\n",
    "\n",
    "    # 处理文档的函数\n",
    "    def splitSentences(self):\n",
    "        full_text = self.getFile()  # 获取文档内容\n",
    "        if full_text is not None:\n",
    "            # 对文档进行分割\n",
    "            text_split = CharacterTextSplitter(\n",
    "                chunk_size=150,\n",
    "                chunk_overlap=20,\n",
    "            )\n",
    "            texts = text_split.split_documents(full_text)\n",
    "            self.splitText = texts\n",
    "\n",
    "    # 向量化与向量存储\n",
    "    def embeddingAndVectorDB(self):\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "        db = Chroma.from_documents(\n",
    "            documents=self.splitText,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=\"./chroma_db\"  # v1.0 推荐指定持久化目录\n",
    "        )\n",
    "        return db\n",
    "\n",
    "    # 提问并找到相关的文本块\n",
    "    def askAndFindFiles(self, question):\n",
    "        db = self.embeddingAndVectorDB()\n",
    "        # retriever = db.as_retriever(search_type=\"mmr\")\n",
    "        retriever = db.as_retriever(\n",
    "            search_type=\"similarity_score_threshold\",\n",
    "            search_kwargs={\"score_threshold\": 0.5, \"k\": 1}\n",
    "        )\n",
    "        return retriever.invoke(question)  # v1.0 使用 invoke 方法\n",
    "\n",
    "    # 用自然语言和文档聊天\n",
    "    def chatWithDoc(self, question):\n",
    "        _content = \"\"\n",
    "        context = self.askAndFindFiles(question)\n",
    "        for i in context:\n",
    "            _content += i.page_content\n",
    "\n",
    "        messages = self.prompt.format_messages(context=_content, question=question)\n",
    "        chat = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo:free\",\n",
    "            base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "            temperature=0 # 温度是指的模型输出结果的随机性。分数越高，输出结果越随机。\n",
    "        )\n",
    "        return chat.invoke(messages)\n",
    "\n",
    "\n",
    "chat_doc = ChatDoc()\n",
    "chat_doc.doc = \"resource/example/fake.docx\"\n",
    "chat_doc.splitSentences()\n",
    "result = chat_doc.chatWithDoc(\"公司注册地址是哪里？\")\n",
    "print(result.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "公司注册地址是江苏省南京市雨花台区软件大道101号。\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
