{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 多Agnet\n",
   "id": "33971c5ea61b973"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T03:40:50.016931Z",
     "start_time": "2025-11-10T03:40:37.992859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tabnanny import verbose\n",
    "\n",
    "from langchain_classic.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain_classic.chains.llm import LLMChain\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "from langchain_core.tools import create_retriever_tool, tool\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from docutils.nodes import document\n",
    "from langchain_community.document_loaders import TextLoader, WebBaseLoader\n",
    "import os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "# 尝试这个导入路径\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "def create_first_agent():\n",
    "    # 创建一个消息历史对象\n",
    "    message_history = ChatMessageHistory()\n",
    "    # 创建一个文档加载器\n",
    "    loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "    docs = loader.load()\n",
    "    # 创建一个文档分割器,参数是1000和200，代表每个文档的块大小和块重叠大小\n",
    "    documents = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, chunk_overlap=200\n",
    "    ).split_documents(docs)\n",
    "    # 使用本地嵌入模型替代 OpenAI embeddings\n",
    "    # 创建一个向量数据库,参数是document和embeddings,代表文档和嵌入模型\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vector = FAISS.from_documents(documents, embeddings)\n",
    "    # 创建一个向量数据库检索器\n",
    "    retriever = vector.as_retriever()\n",
    "    # 创建一个向量数据库检索器工具\n",
    "    retriever_tool = create_retriever_tool(\n",
    "        retriever,\n",
    "        \"langsmith_search\",\n",
    "        \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    "    )\n",
    "\n",
    "    # 使用新的 TavilySearch 类\n",
    "    search = TavilySearch()\n",
    "\n",
    "    tools = [search, retriever_tool]\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-3.5-turbo:free\",\n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        temperature=0 # 温度是指的模型输出结果的随机性。分数越高，输出结果越随机。\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are a helpful assistant.\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "        ]\n",
    "    )\n",
    "    # 创建一个Agnet\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    # 创建一个AgentExecutor\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "    # Runnable是一个可运行对象，可以运行一个函数，也可以运行一个Agent，lambda用于创建一个可运行对象\n",
    "    agent_with_chat_history = RunnableWithMessageHistory(\n",
    "        agent_executor,\n",
    "        lambda session_id: message_history,\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key='chat_history',\n",
    "    )\n",
    "    return agent_with_chat_history\n",
    "\n",
    "# 创建一个基础计算器工具\n",
    "@tool\n",
    "def basic_calculator(query):\n",
    "    \"\"\"Basic calculator tool\"\"\"\n",
    "    try:\n",
    "        result = eval(query)\n",
    "        return f\"The result is {result}\"\n",
    "    except (SyntaxError, NameError) as e:\n",
    "        return f\"Sorry, I couldn't calculate that due to an error: {e}\"\n",
    "\n",
    "\n",
    "# 创建一个方程求解工具\n",
    "@tool\n",
    "def equation_solver(query):\n",
    "    \"\"\"Equation solver tool\"\"\"\n",
    "    # Basic equation solver (placeholder)\n",
    "    # Implement specific logic for solving equations\n",
    "    return \"Equation solver: This feature is under development.\"\n",
    "\n",
    "\n",
    "def create_second_agent():\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini:free\",\n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    tools = [basic_calculator, equation_solver]\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"你很擅长解决与数学相关的问题。请将问题的答案返回给用户\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    message_history = ChatMessageHistory()\n",
    "    # 给智能体（Agent）添加 “对话历史记忆” 能力\n",
    "    agent_with_chat_history = RunnableWithMessageHistory(\n",
    "        agent_executor,\n",
    "        lambda session_id: message_history,\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key='chat_history',\n",
    "    )\n",
    "    return agent_with_chat_history\n",
    "\n",
    "def get_agent(user_input):\n",
    "     template = \"You are a helpful assistant. Classify the user input as either 'math' if it's math-related or 'general/technical' otherwise. respond directly with the classification. Question: {question}\"\n",
    "     prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "     llm = ChatOpenAI(\n",
    "        model=\"gpt-3.5-turbo:free\",\n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "     llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "     response = llm_chain.invoke({\"question\": user_input})\n",
    "     return  response[\"text\"].strip().lower()  # 标准化返回值\n",
    "\n",
    "def main():\n",
    "    load_dotenv()\n",
    "    # create agents\n",
    "    technical_agent = create_first_agent()\n",
    "    math_agent = create_second_agent()\n",
    "    user_input = input(\"请输入问题：\")\n",
    "\n",
    "    response = get_agent(user_input)\n",
    "    if \"math\" in response:\n",
    "        print(\"invoking math agent\")\n",
    "        # Run the math agent\n",
    "        math_agent.invoke(\n",
    "            {\"input\": user_input},\n",
    "            config={\"configurable\": {\"session_id\": \"test\"}},\n",
    "        )\n",
    "    else:\n",
    "        print(\"invoking technical agent\")\n",
    "        # Run the technical agent\n",
    "        technical_agent.invoke(\n",
    "            {\"input\": user_input},\n",
    "            config={\"configurable\": {\"session_id\": \"test\"}},\n",
    "        )\n",
    "\n",
    "# 运行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "24d2887ea32923f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for TavilySearchAPIWrapper\n  Value error, Did not find tavily_api_key, please add an environment variable `TAVILY_API_KEY` which contains it, or pass `tavily_api_key` as a named parameter. [type=value_error, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 169\u001B[0m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;66;03m# 运行主函数\u001B[39;00m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 169\u001B[0m     main()\n",
      "Cell \u001B[0;32mIn[1], line 147\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m    145\u001B[0m load_dotenv()\n\u001B[1;32m    146\u001B[0m \u001B[38;5;66;03m# create agents\u001B[39;00m\n\u001B[0;32m--> 147\u001B[0m technical_agent \u001B[38;5;241m=\u001B[39m create_first_agent()\n\u001B[1;32m    148\u001B[0m math_agent \u001B[38;5;241m=\u001B[39m create_second_agent()\n\u001B[1;32m    149\u001B[0m user_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m请输入问题：\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[1], line 45\u001B[0m, in \u001B[0;36mcreate_first_agent\u001B[0;34m()\u001B[0m\n\u001B[1;32m     38\u001B[0m retriever_tool \u001B[38;5;241m=\u001B[39m create_retriever_tool(\n\u001B[1;32m     39\u001B[0m     retriever,\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlangsmith_search\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSearch for information about LangSmith. For any questions about LangSmith, you must use this tool!\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     42\u001B[0m )\n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# 使用新的 TavilySearch 类\u001B[39;00m\n\u001B[0;32m---> 45\u001B[0m search \u001B[38;5;241m=\u001B[39m TavilySearch()\n\u001B[1;32m     47\u001B[0m tools \u001B[38;5;241m=\u001B[39m [search, retriever_tool]\n\u001B[1;32m     49\u001B[0m llm \u001B[38;5;241m=\u001B[39m ChatOpenAI(\n\u001B[1;32m     50\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-3.5-turbo:free\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     51\u001B[0m     base_url\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOPENAI_BASE_URL\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     52\u001B[0m     api_key\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOPENAI_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     53\u001B[0m     temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m \u001B[38;5;66;03m# 温度是指的模型输出结果的随机性。分数越高，输出结果越随机。\u001B[39;00m\n\u001B[1;32m     54\u001B[0m )\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.13/site-packages/langchain_tavily/tavily_search.py:343\u001B[0m, in \u001B[0;36mTavilySearch.__init__\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    340\u001B[0m         wrapper_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapi_base_url\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapi_base_url\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    341\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapi_wrapper\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m TavilySearchAPIWrapper(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mwrapper_kwargs)\n\u001B[0;32m--> 343\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.13/site-packages/langchain_core/tools/base.py:515\u001B[0m, in \u001B[0;36mBaseTool.__init__\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    510\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    511\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margs_schema must be a subclass of pydantic BaseModel or \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    512\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma JSON schema dict. Got: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124margs_schema\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    513\u001B[0m     )\n\u001B[1;32m    514\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 515\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.13/site-packages/langchain_core/load/serializable.py:116\u001B[0m, in \u001B[0;36mSerializable.__init__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    115\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\"\"\"\u001B[39;00m  \u001B[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001B[39;00m\n\u001B[0;32m--> 116\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/lib/python3.13/site-packages/pydantic/main.py:253\u001B[0m, in \u001B[0;36mBaseModel.__init__\u001B[0;34m(self, **data)\u001B[0m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001B[39;00m\n\u001B[1;32m    252\u001B[0m __tracebackhide__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 253\u001B[0m validated_self \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__pydantic_validator__\u001B[38;5;241m.\u001B[39mvalidate_python(data, self_instance\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m validated_self:\n\u001B[1;32m    255\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    256\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA custom validator is returning a value other than `self`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    257\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReturning anything other than `self` from a top level model validator isn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt supported when validating via `__init__`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    259\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m    260\u001B[0m     )\n",
      "\u001B[0;31mValidationError\u001B[0m: 1 validation error for TavilySearchAPIWrapper\n  Value error, Did not find tavily_api_key, please add an environment variable `TAVILY_API_KEY` which contains it, or pass `tavily_api_key` as a named parameter. [type=value_error, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7efda945fe7997d5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
